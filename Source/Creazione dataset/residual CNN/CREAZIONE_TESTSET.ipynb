{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e864c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b5a367ac",
   "metadata": {},
   "source": [
    "# Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8aa94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version, sys.platform, sys.executable)\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.utils import _triple\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch import nn, optim\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchviz import make_dot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import *\n",
    "import pylab\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "import gc\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ec2ff",
   "metadata": {},
   "source": [
    "# Crezione dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Propriet√† input e device:\n",
    "\n",
    "CLIP_LEN, RESIZE_HEIGHT, CROP_SIZE = 10, 128, 112\n",
    "resize_height = RESIZE_HEIGHT\n",
    "crop_size = CROP_SIZE\n",
    "clip_len = CLIP_LEN\n",
    "\n",
    "device = torch.device('cpu')#('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def center_crop(image):\n",
    "        height_index = math.floor((image.shape[0] - crop_size) / 2)\n",
    "        width_index = math.floor((image.shape[1] - crop_size) / 2)\n",
    "        image = image[height_index:height_index + crop_size, width_index:width_index + crop_size, :]\n",
    "        return np.array(image).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846703e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Creazione_VideoTestset(Dataset):\n",
    "\n",
    "    def __init__(self, directory, mode='train', clip_len=8, num_sec=8, cond=\"\"):\n",
    "        folder = Path(directory)\n",
    "        self.type = cond\n",
    "        self.clip_len = clip_len-1\n",
    "        \n",
    "        self.num_sec=num_sec\n",
    "        \n",
    "        # the following three parameters are chosen as described in the paper section 4.1\n",
    "        self.resize_height = 128/2  \n",
    "        self.resize_width = 171/2\n",
    "        self.crop_size = 112/2\n",
    "\n",
    "        # obtain all the filenames of files inside all the class folders \n",
    "        # going through each class folder one at a time\n",
    "        self.fnames, labels = [], []\n",
    "        for label in sorted(os.listdir(folder)):\n",
    "            for fname in os.listdir(os.path.join(folder, label)):\n",
    "                self.fnames.append(os.path.join(folder, label, fname))\n",
    "                labels.append(label)\n",
    "                \n",
    "        # prepare a mapping between the label names (strings) and indices (ints)\n",
    "        self.label2index = {label:index for index, label in enumerate(sorted(set(labels)))} \n",
    "        \n",
    "        # convert the list of label names into an array of label indices\n",
    "        self.label_array = np.array([self.label2index[label] for label in labels], dtype=int)        \n",
    "        #create_dataset()\n",
    "        \n",
    "    def create_dataset(self):\n",
    "        count = 0\n",
    "        clips = []\n",
    "        clip = []\n",
    "        prev_label = -1\n",
    "        os.mkdir('testset'+ self.type +'_'+\"num_sec_\"+str(self.num_sec)+\"_FPS_\"+str((self.clip_len+1)/self.num_sec))\n",
    "        \n",
    "        for i in np.arange(len(self.fnames)):\n",
    "            if(self.label_array[i] != prev_label):\n",
    "                count = 0\n",
    "                os.mkdir('testset'+ self.type +'_'+\"num_sec_\"+str(self.num_sec)+\"_FPS_\"+str((self.clip_len+1)/self.num_sec)+'/'+str(self.label_array[i]))\n",
    "            os.mkdir('testset'+ self.type +'_'+\"num_sec_\"+str(self.num_sec)+\"_FPS_\"+str((self.clip_len+1)/self.num_sec)+'/'+str(self.label_array[i])+'/'+str(count))\n",
    "            clip = self.loadvideo(self.fnames[i], i, count)\n",
    "            \n",
    "            count = count + 1\n",
    "            prev_label = self.label_array[i]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        buffer = []\n",
    "        # loading and preprocessing. TODO move them to transform classes\n",
    "        buffer = self.loadvideo(self.fnames[index])\n",
    "        control = buffer != []\n",
    "        if control:\n",
    "            buffer = self.normalize(buffer)\n",
    "            return buffer[0,:,:,:,:], self.label_array[index-1]    \n",
    "        return buffer, self.label_array[index]\n",
    "        \n",
    "    def loadvideo(self, fname, index, count):\n",
    "        self.resize_height = int(128*3/2)\n",
    "        self.resize_width = int(171*3/2)\n",
    "        self.crop_size = int(112*3/2)\n",
    "        \n",
    "        cap, retaining, clips = cv2.VideoCapture(fname), True, []\n",
    "        \n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(frame_count)\n",
    "        frame_count = self.num_sec*frame_count/8\n",
    "        buffer = []\n",
    "        i = -1\n",
    "        frame_collect = 0\n",
    "        if(self.clip_len != 0):\n",
    "            counter = counter = (int)(frame_count/self.clip_len)\n",
    "            \n",
    "            if(counter < 2):\n",
    "                counter = 1\n",
    "        while retaining:\n",
    "            \n",
    "            i = i+1\n",
    "            retaining, frame = cap.read()\n",
    "            \n",
    "            if not retaining and frame is None:\n",
    "\n",
    "                continue\n",
    "            if(i == 0 and self.clip_len == 0):\n",
    "                resize_width = math.floor(frame.shape[1] / frame.shape[0] * self.resize_height)\n",
    "                # make sure it can be cropped correctly\n",
    "                control3 = self.resize_width < self.crop_size\n",
    "                if control3:\n",
    "                    self.resize_width = self.resize_height\n",
    "                    self.resize_height = math.floor(frame.shape[0] / frame.shape[1] * self.resize_width)\n",
    "                    \n",
    "                tmp = center_crop(cv2.resize(frame, (self.resize_width, self.resize_height)))\n",
    "               \n",
    "                \n",
    "                cv2.imwrite('testset'+ self.type +'_'+\"num_sec_\"+str(self.num_sec)+\"_FPS_\"+str((self.clip_len+1)/self.num_sec)+'/'+str(self.label_array[index])+'/'+str(count)+\"/\"+str(self.label_array[index])+'_'+str(frame_collect)+'.jpg', tmp)\n",
    "                \n",
    "                cap.release()\n",
    "                return buffer\n",
    "            \n",
    "            control = ((i % counter == 0) and frame_collect<=self.clip_len) #and (np.shape(buffer))\n",
    "\n",
    "            #if(buffer)\n",
    "            if control:\n",
    "                frame_collect = frame_collect + 1\n",
    "                resize_width = math.floor(frame.shape[1] / frame.shape[0] * self.resize_height)\n",
    "                # make sure it can be cropped correctly\n",
    "                control3 = self.resize_width < self.crop_size\n",
    "                if control3:\n",
    "                    self.resize_width = self.resize_height\n",
    "                    self.resize_height = math.floor(frame.shape[0] / frame.shape[1] * self.resize_width)\n",
    "                    \n",
    "                tmp = center_crop(cv2.resize(frame, (self.resize_width, self.resize_height)))\n",
    "                \n",
    "                cv2.imwrite('testset'+ self.type +'_'+\"num_sec_\"+str(self.num_sec)+\"_FPS_\"+str((self.clip_len+1)/self.num_sec)+'/'+str(self.label_array[index])+'/'+str(count)+\"/\"+str(self.label_array[index])+'_'+str(frame_collect)+'.jpg', tmp)\n",
    "            float_control = False\n",
    "            control2 = (i == frame_count-1 and float_control == True and frame_collect == self.clip_len )\n",
    "            if control2:\n",
    "                frame_collect = frame_collect + 1\n",
    "                resize_width = math.floor(frame.shape[1] / frame.shape[0] * self.resize_height)\n",
    "                # make sure it can be cropped correctly\n",
    "                control3 = self.resize_width < self.crop_size\n",
    "                if control3:\n",
    "                    self.resize_width = self.resize_height\n",
    "                    self.resize_height = math.floor(frame.shape[0] / frame.shape[1] * self.resize_width)\n",
    "                    \n",
    "                tmp = center_crop(cv2.resize(frame, (self.resize_width, self.resize_height)))\n",
    "                cv2.imwrite('testset'+ self.type +'_'+\"num_sec_\"+str(self.num_sec)+\"_FPS_\"+str((self.clip_len+1)/self.num_sec)+'/'+str(self.label_array[index])+'/'+str(count)+\"/\"+str(self.label_array[index])+'_'+str(frame_collect)+'.jpg', tmp)\n",
    "                 \n",
    "        cap.release()\n",
    "        print('testset'+ self.type +'_'+\"num_sec_\"+str(self.num_sec)+\"_FPS_\"+str((self.clip_len+1)/self.num_sec)+'/'+str(self.label_array[index])+'/'+str(count)+\"/\"+str(self.label_array[index])+'_'+str(frame_collect)+'.jpg')\n",
    "        return []\n",
    "    \n",
    "    def normalize(self, buffer):\n",
    "        # Normalize the buffer>\n",
    "        # NOTE: Default values of RGB images normalization are used, as precomputed \n",
    "        # mean and std_dev values (akin to ImageNet) were unavailable for Kinetics. Feel \n",
    "        # free to push to and edit this section to replace them if found. \n",
    "        buffer = (buffer - 128)/128\n",
    "        return buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b79cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pippo = np.arange(22)+1\n",
    "minni = np.arange(8)+1\n",
    "for i in pippo:\n",
    "    for j in minni:\n",
    "        p = i * j\n",
    "        if(p == 8 or p == 16 or p == 24 or p == 32 or p == 40 or p == 48 or p == 56 or p == 64 or p == 72):\n",
    "                x = Creazione_VideoTestset(\"TestSet/Dataset_Day\", clip_len=j*i, num_sec = j, cond=\"Day\")\n",
    "                x.create_dataset()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
